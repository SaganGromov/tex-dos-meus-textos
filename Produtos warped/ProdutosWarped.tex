% !TeX root = ProdutosWarped.tex

\input{notation.tex}
\input{preambleWarped.tex}

\begin{document}

\PlaceText{69mm}{38mm}{ \color{gal}\noindent\makebox[\linewidth]{\rule{2\paperwidth}{1pt}}}

\PlaceText{69mm}{14.3mm}{ \color{white}\noindent\makebox[\linewidth]{\rule{2\paperwidth}{12pt}}}

\PlaceText{69mm}{15mm}{ \color{gal}\noindent\makebox[\linewidth]{\rule{2\paperwidth}{1pt}}}

\PlaceText{69mm}{19mm}{ \color{white}\noindent\makebox[\linewidth]{\rule{2\paperwidth}{3pt}}}

\PlaceText{73mm}{31mm}{\Huge \textcolor{gal}{\textit{Produtos warped}}}

%\vspace{1cm}

\lettrine[nindent=2em,lines=1]{E}m geral, a grande maioria dos cálculos de Geometria Riemanniana se resumem a provar igualdades tensoriais. Isso geralmente é realizado de uma das três maneiras a seguir:
\begin{itemize}
\item \emph{a maneira livre de coordenadas}: nesse caso, explicitamos a ação de cada tensor em campos arbitrários na variedade em questão, verificando que os resultados coincidem.
\item \emph{usando coordenadas locais}: nesse caso, fixamos coordenadas locais apropriadas que facilitem os cálculos (por exemplo, coordenadas normais) e tomamos vantagem da multilinearidade dos tensores, que garante que a igualdade só precisa ser verificada numa base (conforme detalhado em \mycitep{MeuTextoLivre}). 
\item \emph{usando o método do referencial móvel}: nesse caso, fixamos um referencial ortonormal local (que induz um co-referencial ortonormal local) e calculamos as $1$-formas e $2$-formas de conexão e curvatura, respectivamente, que determinam a conexão e curvatura da variedade.
\end{itemize}
Dependendo da situação, um dos três métodos acima pode ser significativamente mais fácil de ser aplicado do que os outros dois. Nessa subseção, nos dedicaremos, com base na referência \mycitep{TuRiem}, a explorar o suficiente às nossas aplicações do último método citado acima. \par 
Seja $(\mm^n, g)$ uma variedade Riemanniana e fixe $\{\be_1, \ldots, \be_n \}$ um referencial local $g$-ortonormal definido num aberto $U \subset \mm$, sendo $\{\be^1, \ldots, \be^n\}$ o co-referencial associado (determinado por $\be^i(\be_j) = \delta^i_j$). Como qualquer campo $X \in \Gamma(T \mm)$ se escreve localmente como \[\Gamma(TU) \ni  X|_{U} = \sum_{1 \leq j \leq n} X^j \, \be_j, \text{ onde } \{ X^j \}_{1 \leq j \leq n} \subset \mathscr{C}^{\infty}(\mm) \] então dada $s \in \Gamma(TU)$ podemos determinar (usando a linearidade de $\nabla$ na primeira entrada e a regra de Leibniz) $\nabla_X s$ pelo conhecimento dos campos $\{\nabla_X \be_j \}_{1 \leq j \leq n}$. Sendo um campo em $U$, $\nabla_X \be_j$ é uma combinação linear dos $\be_i$'s com coeficientes $\omega^{i}_j$ dependendo de $X$, \emph{id est:}
\[ 
\nabla_X \be_j = \sum_{1 \leq i \leq n} \omega^{i}_j(X) \, \be_i
\]
A $\mathscr{C}^{\infty}(\mm)$-linearidade de $\nabla_X \be_j$ em $X$ garante a $\mathscr{C}^{\infty}(\mm)$-linearidade de $\omega^{i}_j$ em $X$, de forma que $\omega^{i}_j \in \Gamma(T^{*} U)$ é uma $1$-forma em $U$. As $1$-formas $\omega^{i}_j$ em $U$ são chamadas das \textbf{\emph{formas de conexão}}, e a matriz $\omega = (\omega^{i}_j)_{1 \leq i, j \leq n}$ é chamada da \textbf{\emph{matriz de conexão}}, da conexão $\nabla$ com respeito ao referencial $\{\be_i \}_{1 \leq i \leq n} \subset \Gamma(T U)$. \par 
Analogamente, dados $X, Y \in \Gamma(T U)$, o campo $\Rm(X, Y)\be_j$ é uma combinação linear de $\be_1, \ldots, \be_n$, \emph{id est:}
\[
\Rm(X, Y) \be_j = \sum_{1 \leq i \leq n} \Omega^{i}_j(X, Y) \, \be_i
\]
Uma vez que
\[
\Rm(X, Y) = \nabla_X \nabla_Y - \nabla_Y \nabla_X - \nabla_{[X, Y]}
\]
é alternada e $\mathscr{C}^{\infty}(\mm)$-bilinear, $\Omega^{i}_j$ também é alternada e $\mathscr{C}^{\infty}(\mm)$-bilinear. Pelas propriedades de $\Rm$, $\Omega^{i}_j$ é portanto uma $2$-forma em $U$. As $2$-formas $\Omega^{i}_j$ são chamadas das \textbf{\textit{formas de curvatura}}, e a matriz $\Omega = (\Omega^{i}_j)$ é chamada da matriz de curvatura, da conexão $\nabla$ com respeito ao referencial $\{\be_1, \ldots, \be_n \}$ em $U$. 
\begin{oobs}
Note que $\Omega^{i}_j$ é determinada por $\Rm$, pois
\[ \begin{aligned}
\Omega^{i}_j &= \frac{1}{2} \, \sum_{1 \leq k, \ell \leq n}  \, \Omega^i_j(\be_k, \be_{\ell}) \, \be^k \wedge \be^{\ell} \\
&= -\frac{1}{2} \,  \sum_{1 \leq k, \ell \leq n} \Rm(\be_i, \be_j, \be_k, \be_{\ell})  \, \be^k \wedge \be^{\ell}
\end{aligned}
\]
onde a última igualdade segue do fato de que 
\[
\begin{aligned}
\Omega^i_j(\be_k, \be_{\ell}) &= g\left( \sum_{1 \leq t \leq n} \Omega^{s}_j(\be_k, \be_{\ell}) \be_s, \be_i \right) \\
&= g\left( \Rm(\be_k, \be_{\ell}) \be_j, \be_i \right) \\
&= - \Rm(\be_i, \be_j, \be_k, \be_{\ell})
\end{aligned}
\]
\end{oobs}
Cálculos diretos mostram os seguintes resultados:
\begin{teorema}\label{PrimeiraUnicaCartan}
Seja $(\mm^n, g)$ uma variedade Riemanniana e $U \subset \mm$ um aberto em qual está definido um referencial ortonormal $\be_1, \ldots, \be_n$, com co-referencial associado $\be^1, \ldots, \be^n$. Então existe uma matriz antissimétrica $\left(\omega^{i}_j \right)_{1 \leq i, j \leq n}$ de $1$-formas tal que
\[
\dd \be^i + \sum_{1 \leq j \leq n} \omega^{i}_j \wedge \be^j = 0, \text{ seja qual for } 1 \leq i \leq n
\]
Além disso, se $\left(\alpha^{i}_j \right)_{1 \leq i, j \leq n}$ é qualquer outra matriz antissimétrica de $1$-formas satisfazendo
\begin{equation}
\dd \be^i + \sum_{1 \leq j \leq n} \alpha^{i}_j \wedge \be^j = 0, \text{ seja qual for } 1 \leq i \leq n
\end{equation} então \[ \left(\alpha^{i}_j \right)_{1 \leq i, j \leq n} = \left(\omega^{i}_j \right)_{1 \leq i, j \leq n} \]
\end{teorema}
\begin{teorema}\label{SegEqEstrCartan}
As formas de curvatura $\Omega^{i}_j$ se relacionam às formas de conexão $\omega^{i}_j$ pela seguinte equação, comumente chamada da \textbf{segunda equação estrutural de Cartan}:
\[
\Omega^{i}_j = \dd \, \omega^{i}_j + \sum_{1 \leq k \leq n} \omega^{i}_k \wedge \omega^k_j, \text{ sejam quais forem } \{i, j\} \subset \{1, \ldots, n \}
\]
\end{teorema}
\begin{demm}
Consulte \mycitep{TuRiem}.
\end{demm}


Um dos conceitos mais importantes e frutíferos de geometria Riemanniana é o \emph{produto warped} de variedades Riemannianas, que generaliza o produto Riemanniano comum. Tal conceito também tem grande relevância na física, aparecendo na teoria da relatividade como modelo do próprio Cosmos ou de buracos negros (veja, por exemplo, o modelo cosmológico de Friedmann–Lemaître–Robertson–Walker). 


\begin{deff}
Sejam $(\bb, g_{B})$ e $(\mm_i, g_{\mm_i})$ variedades Riemannianas e $b_i: \bb \to (0, \infty)$ funções suaves para cada $i \in \{1, 2, \cdots, k \}$. O produto warped múltiplo de tais variedades é a variedade produto $\nn = \bb \times \mm_1 \times \mm_2 \times \cdots \times \mm_k $ munida da métrica $g = g_{\bb} \oplus b_1^2 g_{\mm_1} \oplus b_2^2 g_{\mm_2} \oplus \cdots \oplus b_{k}^2 g_{\mm_k}$ definida por
\[
g = \sigma_0^{*} (g_{\bb}) \oplus \left(b_1 \circ \pi \right)^2 \sigma_1^{*}\left(g_{\mm_1} \right ) \oplus \cdots \oplus \left(b_k \circ \pi \right)^2 \sigma_{k}^{*} \left( g_{\mm_k} \right)
\]
onde $\sigma_0 : \nn \to \bb$ é a aplicação definida por
\begin{align*}
\sigma_0: \nn &\to \bb \\
(p, q_1, \cdots, q_k) &\mapsto p \in \bb
\end{align*}
e para $i \geq 1$, $\sigma_i : \nn \to \mm_i$ é a aplicação definida por
\begin{align*}
\sigma_i: \nn &\to \mm_i \\
(p, q_1, \cdots, q_i, \cdots, q_k) &\mapsto q_i \in \mm_i
\end{align*}
\end{deff}


\begin{oobs}
\begin{itemize} \item É comum denotar a variedade Riemanniana $(\nn  =  \bb \times \mm_1 \times \mm_2 \times \cdots \times \mm_k, g = g_{\bb} \oplus b_1^2 g_{\mm_1} \oplus b_2^2 g_{\mm_2} \oplus \cdots \oplus b_{k}^2 g_{\mm_k})$ simplesmente por $\nn = \bb \times_{h_1} \mm_1^{d_1} \times \cdots \times_{h_k} \mm_{k}^{d_k}$
\item Quando $k = 1$, temos o produto warped simples usual. 
\item Se todos $b_i \equiv 1$, temos um produto Riemanniano trivial. 
\end{itemize}
\end{oobs}

\begin{deff}
Se $\varphi: \mm \to \nn$ é uma aplicação suave, diremos que dois campos $X \in \Gamma(T \mm)$ e $Y \in \Gamma(T \nn)$ estão $\varphi$-relacionados (fato que denotaremos por $X \overset{\varphi}{\sim} Y$) quando $Y \circ \varphi = \dd \varphi \circ X$.
\end{deff}


\begin{lema}
O espaço tangente $T_p \mm$ de um ponto $p = (p_0, p_1, \cdots, p_k) \in \mm = \bb \times \nn_1 \times \cdots \times \nn_k$ é canonicamente isomorfo (no sentido de existir um isomorfismo que não depende de escolhas de bases) ao produto $T_{p_0} \bb \times T_{p_1} \nn_1 \times \cdots \times T_{p_k} \nn_k$. 
\end{lema}

\begin{demm}
Considere as aplicações
\begin{align*}
\iota_0 : \bb &\to \mm \\
\bb \ni q_0 &\mapsto \parent{q_0, p_1, \ldots, p_k} \in \mm
\end{align*}
e, para $\alpha \geq 1$,
\begin{align*}
\iota_{\alpha}: \nn_{\alpha} &\to \mm \\
\nn_{\alpha} \ni q_{\alpha} &\mapsto \parent{ p_0, p_1, \ldots, p_{\alpha - 1}, q_{\alpha}, p_{\alpha + 1}, \ldots, p_k}
\end{align*}
Afirmo que a aplicação $\psi$ definida por
\begin{align*}
\psi: T_{(p_0, p_1, \cdots, p_k)} \parent{\bb \times \nn_1 \times \cdots \times \nn_k}&\to T_{p_0} \bb \times T_{p_1} \nn_1 \times \cdots \times T_{p_k} \nn_k  \\
v &\mapsto \left( \dd \parent{\sigma_0}_{p}(v), \dd \left( \sigma_1 \right)_{p}(v),  \dd \left( \sigma_2 \right)_{p}(v), \cdots, \dd \left( \sigma_k \right)_{p}(v) \right)
\end{align*}
é um isomorfismo, com inversa dada por
\begin{align*}
\varphi: T_{p_0} \bb \times T_{p_1} \nn_1 \times \cdots \times T_{p_k} \nn_k &\to  T_{(p_0, p_1, \cdots, p_k)} \parent{\bb \times \nn_1 \times \cdots \times \nn_k }\\
\parent{v_0, v_1, \ldots, v_k} &\mapsto \sum_{0 \leq \ell \leq k}\dd \parent{\iota_{\ell}}_{p_{\ell}}\parent{v_{\ell}}
\end{align*}  
Inicialmente, note que
\[
\sigma_i \circ \iota_{\ell} = \begin{cases}
\text{a aplicação identidade } \Id_{\nn_i} : \nn_i \to \nn_i, \text{ se $i = \ell$ } \\
\text{a aplicação constante } \nn_{\ell} \ni q_{\ell} \mapsto p_i \in \nn_i, \text{ se $i \neq \ell$}
\end{cases}
\]
E portanto, segue da regra da cadeia que
\begin{equation}\label{RegCadL116}
\begin{aligned}
\dd \parent{\sigma_i \circ \iota_{\ell}  }_{p_{\ell}} &= \dd \parent{ \sigma_i }_p \circ \dd \parent{\iota_{\ell}}_{p_{\ell}} \\
&=\begin{cases}
\text{a aplicação identidade } \Id_{T_{p_{i}}\nn_{i}} : T_{p_{i}}\nn_i \to T_{p_{i}}\nn_i, \text{ se $i = \ell$ } \\
\text{a aplicação identicamente nula } T_{p_{\ell}} \nn_{\ell} \ni v_{\ell} \mapsto 0 \in  T_{p_{\ell}} \nn_{\ell}, \text{ se $i \neq \ell$}
\end{cases}
\end{aligned}
\end{equation}
Portanto, seja qual for $\parent{v_0, v_1, \ldots, v_k} \in T_{p_0} \bb \times T_{p_1} \nn_1 \times \cdots \times T_{p_k} \nn_k$, temos
\begin{align*}
\parent{\psi \circ \varphi} \parent{v_0, v_1, \ldots, v_k} &= \parent{ \dd \parent{\sigma_0}_p \parent{  \sum_{0 \leq \ell \leq k}\dd \parent{\iota_{\ell}}_{p_{\ell}}\parent{v_{\ell}}} , \ldots,\dd \parent{\sigma_k}_p \parent{  \sum_{0 \leq \ell \leq k}\dd \parent{\iota_{\ell}}_{p_{\ell}}\parent{v_{\ell}}}  } \\
&=\parent{\sum_{0 \leq \ell \leq k} \dd \parent{\sigma_0}_p \parent{ \dd \parent{\iota_{\ell}}_{p_{\ell}}\parent{v_{\ell}}}, \ldots, \sum_{0 \leq \ell \leq k} \dd \parent{\sigma_k}_p \parent{ \dd \parent{\iota_{\ell}}_{p_{\ell}}\parent{v_{\ell}}} } \\
&=\parent{v_0, v_1, \ldots, v_k}
\end{align*}
onde na última igualdade usamos \cref{RegCadL116}. Segue que $\psi$ é sobrejetiva. Como $T_{(p_0, p_1, \cdots, p_k)} \parent{\bb \times \nn_1 \times \cdots \times \nn_k}$ e $T_{p_0} \bb \times T_{p_1} \nn_1 \times \cdots \times T_{p_k} \nn_k $ têm a mesma dimensão, segue que $\psi$ é um isomorfismo. Como uma aplicação bijetora possui um único inverso à direita, segue também que $\varphi$ é o inverso de $\psi$. 
\end{demm}


\begin{oobs}
Para cada $i \in \{0, 1, \cdots, k\}$, o conjunto dos campos em $\mm$ que surgem como levantamentos de campos em fatores do produto será denotado por
\[
\mathcal{L}(\nn_i) = \{ X \in \Gamma(T \mm) \ \vert \ \dd \sigma_j (X) = 0, \text{ seja qual for $j\neq i$} \}
\]
Dado $X_i \in \Gamma(T \nn_i)$, é fácil ver que existe um único campo $\text{Lev}(X_i) \in \mathcal{L}(\nn_i) $ que satisfaz $\left( \dd \sigma_i \circ \text{Lev} \right)(X_i) = X_i$ (de fato, $\text{Lev}(X_i) = \psi^{-1}\left((0, \cdots, X_i, 0, \cdots, 0) \right)$). O campo $\text{Lev}(X_i)$ é chamado do levantamento do campo $X_i$. O abuso de notação de identificar um campo ou uma $1$-forma com seu levantamento é portanto inofensivo, e o cometeremos várias vezes daqui em diante. Note que $\text{Lev}(X_i)$ é o único campo $\sigma_i$-relacionado com $X_i$ e $\sigma_j$-relacionado com $0 \in \Gamma(T \nn_j)$ para todo $j \neq i$. 
\end{oobs}


\begin{oobs}
Convém agora relembrarmos a equação de Gauss. Dizemos que uma aplicação entre variedades Riemannianas $f: \parent{\mm^n, g_{\mm} } \to \parent{\tioC{\mm}{n+p}, \widetilde{g}_{\tioC{\mm}{n+p}}}$ é uma imersão isométrica quando vale
\[
f^{*}\parent{ \widetilde{g}_{\tioC{\mm}{n+p}} } =  g_{\mm} 
\]
ou, equivalentemente, 
\[
g_{\mm}(p) \parent{ v, w } = \widetilde{g}_{\tioC{\mm}{n+p}}\parent{f(p)} \parent{ \dd f_p(v), \dd f_p(w) }
\]
sejam quais forem $p \in \mm$ e $v, w \in T_{p} \mm$. Nesse caso, cometendo o abuso usual de identificar campos com suas extensões, temos
\begin{equation}\label{EquacaoGauss}
\widetilde{\Rm}(X, Y, Z, W) = \Rm(X, Y, Z, W) - \widetilde{g}_{\tioC{\mm}{n+p}} \parent{ \segf(X, W), \segf(Y, Z) } +  \widetilde{g}_{\tioC{\mm}{n+p}} \parent{ \segf(X, Z), \segf(Y, W) } 
\end{equation}
sejam quais forem $X, Y, Z, W \in \Gamma(T \mm)$. Nesse sentido, é importante ressaltar que, uma vez que fixarmos
\[
p = (p_0, p_1, \ldots, p_k) \in \mm = \bb \times \nn_1 \times \ldots \times \nn_{k}
\]
a inclusão 
\[ \begin{aligned}
\iota_{\alpha}: \parent{ \nn_{\alpha}, g_{\nn_{\alpha}} } &\xhookrightarrow{}  \mm = \bb \times_{h_1} \nn_1 \times \ldots \times_{h_k} \nn_{k} \\
q_{\alpha} &\mapsto  \parent{p_0, \ldots, p_{\alpha - 1}, q_{\alpha}, p_{\alpha + 1}, \ldots, p_k } 
\end{aligned}
\]
\emph{não} é uma imersão isométrica. De fato, fixando arbitrariamente $q_{\alpha} \in \nn_{\alpha}$ e denotando
\[
P = \parent{p_0, \ldots, p_{\alpha - 1}, q_{\alpha}, p_{\alpha + 1}, \ldots, p_k } 
\] 
temos 
\begin{equation}\label{NaoIsometrica}
\begin{aligned}
\left[\parent{\iota_{\alpha}}^{*}\parent{ g_{\mm}} \right](q_{\alpha})\parent{v, w} &= g_{\mm}(P)\parent{ \dd \parent{\iota_{\alpha}}_{q_{\alpha}}\parent{v}, \dd \parent{\iota_{\alpha}}_{q_{\alpha}}\parent{w} } \\
&= h_{\alpha}^2 \parent{p_0} \, \left[\parent{\sigma_{\alpha}}^{*} \parent{ g_{\nn_{\alpha}}} \right]_{P}\parent{ \dd \parent{\iota_{\alpha}}_{q_{\alpha}}\parent{v}, \dd \parent{\iota_{\alpha}}_{q_{\alpha}}\parent{w} }  \\
&= h_{\alpha}^2 \parent{p_0} \, \parent{g_{\nn_{\alpha}}}_{q_{\alpha}} \parent{ \dd \parent{\sigma_{\alpha}}_{P} \parent{\dd \parent{\iota_{\alpha}}_{q_{\alpha}}\parent{v}},  \dd \parent{\sigma_{\alpha}}_{q_{\alpha}} \parent{\dd \parent{\iota_{\alpha}}_{q_{\alpha}}\parent{w}}} \\
&= h_{\alpha}^2 \parent{p_0} \parent{q_{\alpha}} \, \parent{g_{\nn_{\alpha}}}_{q_{\alpha}}\parent{v, w}
\end{aligned}
\end{equation}
onde na última igualdade usamos a equação \cref{RegCadL116}. Porém, é claro dos cálculos feitos em \cref{NaoIsometrica} que com a métrica $ \parent{h_{\alpha}\parent{p_0} }^2 \, g_{\nn_{\alpha}} $, a inclusão
\[ \begin{aligned}
\iota_{\alpha}: \parent{ \nn_{\alpha}, \parent{h_{\alpha}\parent{p_0} }^2 \, g_{\nn_{\alpha}} } &\xhookrightarrow{}  \mm = \bb \times_{h_1} \nn_1 \times \ldots \times_{h_k} \nn_{k} \\
q_{\alpha} &\mapsto  \parent{p_0, \ldots, p_{\alpha - 1}, q_{\alpha}, p_{\alpha + 1}, \ldots, p_k } 
\end{aligned}
\]
\emph{é} uma imersão isométrica, de forma nesse contexto podemos usar a equação \cref{EquacaoGauss} (como faremos futuramente). 
\end{oobs}

\begin{oobs}
Embora usualmente a equação \cref{EquacaoGauss} seja utilizada para determinar a curvatura de subvariedades, em algumas situações podemos usá-la no sentido contrário: ou seja, via o conhecimento da curvatura de específicas subvariedades, podemos determinar a curvatura da variedade total. Um exercício interessante de Geometria Riemanniana (que comentaremos em mais detalhes no exemplo \cref{FormaEspacialComoWarped}) que utiliza essa técnica envolve calcular a curvatura do produto warped $\mathcal{I} \times_{\varphi} \mathbb{Q}^n(\kappa)$, onde $\mathcal{I} \subset \mathbb{R}$ é um intervalo, $\varphi: \mathcal{I} \to (0, \infty)$ é uma função suave, e definimos
\[
\mathbb{Q}^n(\kappa) \doteq \begin{cases}
\mathbb{R}^n, \text{ se } \kappa = 0 \\
\mathbb{S}^n, \text{ se } \kappa = 1 \\
\mathbb{H}^n, \text{ se } \kappa = -1 
\end{cases}
\]
\end{oobs}
\begin{lema}\label{PushBrack}
Se $\varphi: \mm \to \nn$ é uma aplicação suave, então
\[
\dd \varphi([X, Y]) = [\dd \varphi(X), \dd \varphi (Y)], \ \forall X, Y \in \Gamma(T \mm)
\]
\end{lema}

\begin{demm}
Segue da definição do colchete de Lie e da definição da diferencial de uma aplicação. De fato, para qualquer $p \in \mm$ e $g \in \mathscr{C}^{\infty}(\nn)$ temos
\begin{align*}
\left( \dd \varphi_p\left([X, Y](p) \right) \right)(g) &= [X, Y](p) (g \circ \varphi) \\
&= X_p\left( Y(g \circ \varphi) \right) -  Y_p\left( X(g \circ \varphi) \right) \\
&= X_p \left( \dd \varphi(Y)(g) \circ \varphi \right) - Y_p \left( \dd \varphi(X)(g) \circ \varphi \right) \\ 
&= \dd \varphi_p(X_p)\left( \dd \varphi(Y)(g) \right) -  \dd \varphi_p(Y_p)\left( \dd \varphi(X)(g) \right) \\
&= [\dd \varphi (X), \dd \varphi(Y)]_p(g)
\end{align*}
\end{demm}

\begin{lema}\label{RelBrack}
Se $\varphi: \mm \to \nn$ é uma aplicação suave e $X_1, X_2 \in \Gamma(T \mm), Y_1, Y_2 \in \Gamma(T \nn)$ são campos satisfazendo $X_i \stackrel{\varphi}{\sim} Y_i$ para cada $1 \leq i \leq 2$, então $[X_1, X_2] \stackrel{\varphi}{\sim} [Y_1, Y_2]$. 
\end{lema}

\begin{demm}
Consequência imediata do lema anterior. De fato, dado qualquer $p \in \mm$ temos
\begin{align*}
\dd \varphi_p \left( [X_1, X_2](p) \right) &= \left[ \dd \varphi_p \left( X_1(p) \right),  \dd \varphi_p \left( X_2(p) \right) \right] \\
&= [Y_1, Y_2](\varphi(p))
\end{align*}
\end{demm}
Naturalmente, o conhecimento das conexões e curvaturas dos fatores de tal produto determina a conexão e curvatura do próprio produto. Para determinar estes, usaremos o método do referencial móvel. Antes, estabeleceremos algumas notações importantes para as demonstrações dos lemas a seguir (enunciados também em \mycitep{dascontaswarped} - com um erro de sinal no item (8) da Proposição 2.4, corrigido no \cref{sinalerrado} do lema \cref{RmDoWarped}). \par 
Seja $\mm = \bb \times_{h_1} \nn_1^{d_1} \times \cdots \times_{h_k} \nn_{k}^{d_k}$ um produto warped múltiplo com métrica \[ g = g_{\bb} \oplus h_1^2 g_{\nn_1} \oplus \cdots \oplus h_{k}^2 g_{\nn_k} \] e conexão $\nabla^g = \nabla$. Denotaremos $\nn^r_0 \doteq \mathcal{B}$ e $d_i \doteq \dim(\nn_i)$ para cada $0 \leq i \leq k$. Para cada $0 \leq i \leq n$, fixaremos referenciais locais $g_{\nn_i}$-ortonormais, que denotaremos por $\{ \be_{(i, j)} \}_{1 \leq j \leq d_i}$. Seus co-referenciais associados serão denotados por $\{\Theta^{(i, j)} \}_{1 \leq i, j \leq d_i}$ (e estão determinados por $\Theta^{(i, j)}( \be_{(i, s)}) = \delta^j_s$). As $1$-formas de conexão e $2$-formas de curvatura associadas a tais referenciais serão denotadas por $\{ \omega^{(i, j)}_{q} \}_{1 \leq j, q \leq d_i}$ e $ \{ \Omega^{(i, j)}_{q} \}_{1 \leq j, q \leq d_i}$, respectivamente. Sendo assim, note que
\[
\left\{\be_{(0, 1)}, \ldots, \be_{(0, r)}, \frac{1}{h_1} \, \be_{(1, 1)}, \ldots,  \frac{1}{h_1} \, \be_{(1, d_1)}, \ldots, \frac{1}{h_k} \, \be_{(k, 1)}, \ldots,  \frac{1}{h_k} \, \be_{(k, d_k)} \right\}
\]
é um referencial local $g$-ortonormal. Usaremos a notação
\[
\widetilde{\be}_{(i, j)} = \begin{cases}
\be_{(0, j)}, \text{ se } i = 0 \\
\frac{1}{h_i} \, \be_{(i, j)}, \text{ se } i \neq 0
\end{cases}
\]
de forma que
\[
\{ \widetilde{\be}_{(i, j)}\}_{0 \leq i \leq k, 1 \leq j \leq d_i}
\]
é um referencial local $g$-ortonormal, sendo seu co-referencial local associado dado por
\[
\{\widetilde{\Theta}^{(i, j))} \}_{0 \leq i \leq k, 1 \leq j \leq d_i}
\]
onde
\[
\widetilde{\Theta}^{(i, j)} = \begin{cases}
\Theta^{(0, j)}, \text{ se } i = 0 \\
h_i \Theta^{(i, j)} \, \text{, se } i \neq 0
\end{cases}
\]
de forma que num aberto $U \subset \mm$, todo campo $s \in \Gamma(T U)$ se escreve como
\[
\left.s\right|_{U} = \sum_{\substack{0 \leq i \leq k\\
1 \leq j \leq d_i 
}} \widetilde{s}^{(i, j)} \, \widetilde{\be}_{(i, j)} =  \sum_{\substack{0 \leq i \leq k\\
1 \leq j \leq d_i 
}} \widetilde{\Theta}^{(i, j)}(s) \, \widetilde{\be}_{(i, j)}
\]
Finalmente, as $1$-formas de conexão e $2$-formas de curvatura de $(\mm, g)$ com respeito a esse referencial serão denotadas por $ \{ \widetilde{\omega}^{(i, j)}_{(p, m)} \}_{\substack{0 \, \leq i, p \, \leq k\\
1 \, \leq j, m \, \leq d_i 
}}$ e $ \{ \widetilde{\Omega}^{(i, j)}_{(p, m)} \}_{\substack{0 \, \leq i, p \, \leq k\\
1 \, \leq j, m \, \leq d_i 
}}$, de forma que
\[
\nabla_s \left( \widetilde{\be}_{(p, m)} \right) = \sum_{\substack{0 \, \leq i \, \leq k\\
1 \, \leq j \, \leq d_i  
}} \widetilde{\omega}^{(i, j)}_{(p, m)}(s) \, \widetilde{\be}_{(i, j)}
\] e
\[
\Rm(s_1, s_2) \widetilde{\be}_{(p, m)}= \sum_{\substack{0 \, \leq i \, \leq k\\
1 \, \leq j \, \leq d_i  
}} \widetilde{\Omega}^{(i, j)}_{(p, m)}(s_1, s_2) \, \widetilde{\be}_{(i, j)}
\] 
\begin{lema}\label{MovelWarped}
Seguindo a notação acima, seja $\mm = \bb^r \times_{h_1} \nn_1^{d_1} \times \cdots \times_{h_k} \nn_{k}^{d_k}$ um produto warped múltiplo com métrica $g = g_{\bb} \oplus h_1^2 g_{\nn_1} \oplus \cdots \oplus h_{k}^2 g_{\nn_k}$ e conexão $\nabla^g = \nabla$. As $1$-formas de conexão $ \{ \widetilde{\omega}^{(i, j)}_{(p, m)} \}_{\substack{0 \, \leq i, p \, \leq k\\
1 \, \leq j, m \, \leq d_i 
}}$
são dadas por 
\begin{enumerate}[label=\color{blue}\normalfont\textbf{(\alph*)}]
\item\label{letraA118} \[
\widetilde{\omega}^{(0, j)}_{(0, \ell)} = \omega^{(0, j)}_{\ell}, \text{ sejam quais forem $1 \leq j, \ell \leq r$}
\]
\item\label{letraB118} \[ 
\widetilde{\omega}^{(0, j)}_{(\beta, \ell)} = - \frac{\be_{(0, j)}(h_{\beta})}{h_{\beta}} \, \tioC{\Theta}{(\beta, \ell)}, \text{ para quaisquer $1 \leq j \leq r$ e $\beta, \ell \geq 1$}
\]
\item\label{letraC118} \[
\widetilde{\omega}^{(\gamma, j)}_{(0, a)} = \frac{ \be_{(0, a)}(h_{\gamma})}{h_{\gamma}} \, \tioC{\Theta}{(\gamma, j)}, \text{ se $1 \leq \gamma \leq k$ e $1 \leq a, j \leq r$}
\]
\item\label{letraD118}  \[
\widetilde{\omega}^{(\gamma, q)}_{(\beta, p)} = \delta_{\gamma \beta} \, \omega^{(\gamma, q)}_p, \text{ se $1 \leq \gamma, \beta \leq k$ e $1 \leq p, q \leq d_{\gamma}$ }
\]
\end{enumerate}
\end{lema}
\begin{demm}
A ideia da demonstração é clássica: motivados pelo teorema \cref{PrimeiraUnicaCartan}, iremos definir uma matriz antissimétrica $\left(\alpha^{(i, j)}_{(p, m)} \right)_{\substack{0 \leq i, p \leq k\\
1 \leq j, m \leq d_{i} \\
}} $
que satisfaz 
\begin{equation}\label{AlphaUnica}
\begin{cases}
\dd \tioC{\Theta}{(0, j)} + \sum_{1 \leq \ell \leq r} \alpha^{(0, j)}_{(0, \ell)} \wedge \tioC{\Theta}{(0, \ell)} + \sum_{\substack{1\leq \gamma  \leq k\\
1 \leq \beta \leq d_{\gamma}\\
}} \alpha^{(0, j)}_{(\gamma, \beta)} \wedge \tioC{\Theta}{(\gamma, \beta)}= 0 \\
\dd \tioC{\Theta}{(\beta, \gamma)} + \sum_{1 \leq \ell \leq r} \alpha^{(\beta, \gamma)}_{(0, \ell)} \wedge \tioC{\Theta}{(0, \ell)} + \sum_{\substack{1\leq \xi  \leq k\\
1 \leq \eta \leq d_{\xi}\\
}} \alpha^{(\beta, \gamma)}_{(\xi, \eta)} \wedge \tioC{\Theta}{(\xi, \eta)}= 0
\end{cases}
\end{equation}
sejam quais forem $1 \leq j \leq r$, $1 \leq \beta \leq k$, $1 \leq \gamma \leq d_{\beta}$. Da unicidade enunciada no teorema \cref{PrimeiraUnicaCartan}, seguirá que  $\left(\alpha^{(i, j)}_{(p, m)} \right)_{\substack{0 \leq i, p \leq k\\
1 \leq j, m \leq d_{i} \\
}} $ é a matriz de $1$-formas da conexão de Levi-Civita de $\mm$. Uma vez que
\begin{equation}\label{AlphaUnica1}\begin{aligned}
\dd \widetilde{\Theta}^{(0, j)} &= \dd \Theta^{(0,j)} \\
&= - \sum_{1 \leq \ell \leq r} \omega^{(0, j)}_{\ell} \wedge \widetilde{\Theta}^{(0, \ell)}
\end{aligned}
\end{equation}
E também
\begin{equation}\label{AlphaUnica2}
\begin{aligned}
\dd \tioC{\Theta}{(\gamma, j)} &= \dd \left(h_{\gamma} \Theta^{(\gamma, j)} \right) \\
&= \dd h_{\gamma} \wedge \Theta^{(\gamma,j)} + h_{\gamma} \, \dd \Theta^{(\gamma, j)} \\
&= \left( \sum_{1 \leq a \leq r} \be_{(0, a)}\left( h_{\gamma} \right) \, \Theta^{(0, a)} \right) \wedge \Theta^{(\gamma, j)} - h_{\gamma} \sum_{1 \leq \ell \leq d_{\gamma}} \omega^{(\gamma, j)}_{\ell} \wedge \Theta^{(\gamma, \ell)} \\
&= -\sum_{1 \leq a \leq r}  \left( \be_{(0, a)}\left( h_{\gamma} \right) \, \Theta^{(\gamma, j)}  \right) \wedge  \widetilde{\Theta}^{(0, a)} - \sum_{1 \leq \ell \leq d_{\gamma}} \omega^{(\gamma, j)}_{\ell} \wedge \widetilde{\Theta}^{(\gamma, \ell)}  
\end{aligned}
\end{equation}
Definiremos
\begin{align*}
&\alpha^{(0, j)}_{(0, \ell)} = \omega^{(0, j)}_{\ell} \\
&\alpha^{(0, j)}_{(\gamma, \beta)} = -\frac{ \be_{(0, j)}(h_{\gamma})}{h_{\gamma}} \, \tioC{\Theta}{(\gamma, \beta)} \\
&\alpha^{(\beta, \gamma)}_{(0, \ell)} = \frac{\be_{(0, \ell)} (h_{\beta})}{h_{\beta}} \, \tioC{\Theta}{(\beta, \gamma)} \\
&\alpha^{(\beta, \gamma)}_{(\xi, \eta)} = 0, \text{ para qualquer $\xi \geq 1$ com $\xi \neq \beta$}
\end{align*}
É fácil ver que a matriz $\alpha$ assim definida é antissimétrica. Além disso, segue das equações \cref{AlphaUnica1} e \cref{AlphaUnica2} que $\alpha$ assim definida satifaz \cref{AlphaUnica}, donde segue o resultado desejado. 
\end{demm}
\begin{lema}\label{ConexaoDoWarped}
Seja $\mm = \bb \times_{h_1} \nn_1^{d_1} \times \cdots \times_{h_k} \nn_{k}^{d_k}$ um produto warped múltiplo com métrica $g = g_{\bb} \oplus h_1^2 g_{\nn_1} \oplus \cdots \oplus h_{k}^2 g_{\nn_k}$ e conexão $\nabla^g = \nabla$. Suponha que $X, Y \in \mathcal{L}(\bb)$, $ V \in \mathcal{L}(\nn_{\alpha})$ e $W \in \mathcal{L}(\nn_{\eta})$. Então:
\begin{enumerate}[label=\color{blue}\normalfont\textbf{(\theenumi)}]
\item\label{nablaXYWarp} $\nabla_X Y = \nabla^{\bb}_X Y$
\item\label{NablaWarp} $\nabla_X V = \nabla_V X = \frac{X(h_{\alpha})}{h_{\alpha}} V$
\item\label{NablaVWdoWarp} $\nabla_V W = \begin{cases} 0, \text{ se } \alpha \neq \eta \\ \nabla^{\nn_{\eta}}_V W - \frac{g(V, W)}{h_{\eta}} \grad_{\bb} h_{\eta}, \text{ se } \alpha = \eta \end{cases}$
\end{enumerate}
\end{lema}
\begin{demm}
Temos
\begin{align*}
\nabla_X Y &= \nabla_X\left(\sum_{1 \leq a \leq  r} \widetilde{Y}^{(0, a)} \,  \widetilde{\be}_{(0, a)} \right) \\
&= \sum_{1 \leq a \leq r} \left\{  X\left(\widetilde{Y}^{(0, a)} \right)  \widetilde{\be}_{(0, a)} + \widetilde{Y}^{(0, a)} \,  \nabla_X \left( \widetilde{\be}_{(0, a)} \right) \right\} \\
&= \sum_{1 \leq a \leq r} \left\{  X\left(Y^{(0, a)} \right)  \be_{(0, a)} + Y^{(0, a)} \,  \nabla_X \left( \widetilde{\be}_{(0, a)} \right) \right\}
\end{align*}
Agora, note que
\begin{align*}
 \nabla_X \left( \widetilde{\be}_{(0, a)} \right) &=  \sum_{\substack{0 \leq i \leq k\\
1 \leq j \leq d_i 
}}  \widetilde{\omega}^{(i, j)}_{(0, a)}(X) \, \widetilde{\be}_{(i, j)} \\
&= \sum_{1 \leq j \leq r} \widetilde{\omega}^{(0, j)}_{(0, a)}(X) \, \widetilde{\be}_{(0, j)} + \sum_{\substack{1 \leq \gamma \leq k\\
1 \leq j \leq d_{\gamma}
}}  \widetilde{\omega}^{(\gamma, j)}_{(0, a)}(X) \, \widetilde{\be}_{(\gamma, j)} \\
&= \sum_{1 \leq j \leq r} \omega^{(0, j)}_a(X) \, \be_{(0, j)} + \sum_{\substack{1 \leq \gamma \leq k\\
1 \leq j \leq d_{\gamma}
}} \be_{(0, a)} \left(h_{\gamma} \right) \, \Munderbrace{\Theta^{(\gamma, j)}(X)}{=0, \text{ pois } X \in \mathcal{L}(\mathcal{B})} \, \widetilde{\be}_{(\gamma, j)}  \\
&= \nabla^{\mathcal{B}}_{X} \left( \be_{(0, a)} \right)
\end{align*}
Portanto
\begin{align*}
\nabla_X Y &= \sum_{1 \leq a \leq r} \left\{ X\left(Y^{(0, a)} \right)  \be_{(0, a)} + Y^{(0, a)} \,  \nabla_X \left( \be_{(0, a)} \right) \right\} \\
&=\nabla^{\mathcal{B}}_X \left( \sum_{1 \leq a \leq r}  Y^{(0, a)} \, \be_{(0, a)} \right) \\
&= \nabla^{\mathcal{B}}_X Y
\end{align*}
onde na terceira igualdade usamos os itens \ref{letraA118} e \ref{letraC118} do lema \cref{MovelWarped}. Uma vez que $X\left( V^{(\alpha, \beta)} \right) = 0$, temos também

\begin{align*}
\nabla_X{V} &= \nabla_X \left( \sum_{1 \leq \beta \leq d_{\alpha}} \tioC{V}{(\alpha, \beta)} \, \tioB{\be}{(\alpha, \beta)}\right) \\
&= \sum_{1 \leq \beta \leq d_{\alpha}} \left\{ 	X \left(\tioC{V}{(\alpha, \beta)} \right)  \tioB{\be}{(\alpha, \beta)} + \tioC{V}{(\alpha, \beta)} \, \nabla_X\left( \tioB{\be}{(\alpha, \beta)} \right) \right \} \\
&= \sum_{1 \leq \beta \leq d_{\alpha}} \left\{  \frac{X(h_{\alpha})}{h_{\alpha}} \, V^{(\alpha, \beta)} \, \be_{(\alpha, \beta)} + \tioC{V}{(\alpha, \beta)} \, \left( \sum_{1 \leq \ell \leq r}  \Munderbrace{\widetilde{\omega}^{(0, \ell)}_{(\alpha, \beta)} (X)}{=0, \text{ por \ref{letraB118} de \cref{MovelWarped}}} \, \tioB{\be}{(0, \ell)} + \sum_{\substack{1 \leq \gamma \leq k\\
1 \leq s \leq d_{\gamma}
}}\,  \widetilde{\omega}^{(\gamma, s)}_{(\alpha, \beta)} (X) \, \tioB{\be}{(\gamma, s)} \right) \right\} \\
&= \frac{X(h_{\alpha})}{h_{\alpha}} \, V + \sum_{\substack{1 \leq s, \beta \leq d_{\alpha}
}} \Munderbrace{\omega^{(\alpha, s)}_{\beta}(X)}{=0, \text{pois } X \in \mathcal{L}(\mathcal{B})} \, \tioB{\be}{(\alpha, s)} \\
&= \frac{X(h_{\alpha})}{h_{\alpha}} \, V 
\end{align*}
onde na penúltima igualdade usamos o item \ref{letraD118} do lema \cref{MovelWarped}. \par 
Finalmente, usando novamente o lema \cref{MovelWarped}, temos
\begin{align*}
\cn_V W &= \cn_V \parent{ \sum_{1 \leq \beta \leq d_{\eta}} \tioC{W}{(\eta, \beta)} \, \tioB{\be}{(\eta, \beta)} } \\
&= \sum_{1 \leq \beta \leq d_{\eta}}  V\parent{\tioC{W}{(\eta, \beta)} } \, \tioB{\be}{(\eta, \beta)} + \sum_{1 \leq \beta \leq d_{\eta}} \tioC{W}{(\eta, \beta)} \, \cn_V \parent{  \tioB{\be}{(\eta, \beta)} } \\
&=   \sum_{1 \leq \beta \leq d_{\eta}}  V\parent{\tioC{W}{(\eta, \beta)} } \, \tioB{\be}{(\eta, \beta)} + \sum_{1 \leq \beta \leq d_{\eta}} \tioC{W}{(\eta, \beta)} \left\{ \sum_{1 \leq a \leq r}\widetilde{\omega}^{(0, a)}_{(\eta, \beta)} (V) \,  \tioB{\be}{(0, a)}  + \sum_{ \substack{1 \leq \xi \leq k \\
1 \leq \gamma \leq d_{\xi} }}  \widetilde{\omega}^{(\xi, \gamma)}_{(\eta, \beta)} (V) \,  \tioB{\be}{(\xi, \gamma)}    \right\} \\
&=  \sum_{1 \leq \beta \leq d_{\eta}}  V\parent{\tioC{W}{(\eta, \beta)} } \, \tioB{\be}{(\eta, \beta)} + \sum_{1 \leq \beta \leq d_{\eta}} \tioC{W}{(\eta, \beta)} \left\{-\sum_{1 \leq a \leq r} \frac{\be_{(0, a)}\parent{h_{\eta}}}{h_{\eta}} \, \tioC{V}{(\eta, \beta)} \,  \tioB{\be}{(0, a)} + \sum_{1 \leq \gamma \leq d_{\eta}}\omega^{(\eta, \gamma)}_{\beta}(V) \, \tioB{\be}{(\eta, \gamma)} \right\} \\
&= \sum_{1 \leq \beta \leq d_{\eta}}  \colch{ V\parent{\tioC{W}{(\eta, \beta)} } \, \tioB{\be}{(\eta, \beta)} + \tioC{W}{(\eta, \beta)} \, \cn_V \parent{\tioB{\be}{(\eta, \beta)}}}\, - \sum_{1 \leq a \leq r} \frac{\be_{(0, a)}\parent{h_{\eta}}}{h_{\eta}} \, g(V, W) \, \be_{(0, a)} \\
&= \nabla^{\nn_{\eta}}_{ \dd \sigma_{\eta}(V)} W - \delta_{\alpha \eta } \, \frac{g(V, W)}{h_{\eta}} \grad_{\bb} h_{\eta} \\
&=\delta_{\alpha \eta} \parent{\nabla^{\nn_{\eta}}_V W - \frac{g(V, W)}{h_{\eta}} \grad_{\bb} h_{\eta}}
\end{align*}
\end{demm}
\begin{oobs}
A progressão \quotes{natural} após termos calculado as $1$-formas de conexão no lema \cref{MovelWarped} seria usarmos o teorema \cref{SegEqEstrCartan} para calcularmos as $2$-formas de curvatura. Não faremos isso pois para determinarmos $\Rm$, esse caminho é bem mais complicado em comparação a simplesmente usarmos a definição de $\Rm$ nos cálculos, amparados do lema \cref{MovelWarped}. Faremos isso na demonstração do lema \cref{RmDoWarped}.
\end{oobs}

\begin{lema}\label{ConexWarped}
Seja $\mm = \bb \times_{h_1} \nn_1^{d_1} \times \cdots \times_{h_k} \nn_{k}^{d_k}$ um produto warped múltiplo com métrica $g = g_{\bb} \oplus h_1^2 g_{\nn_1} \oplus \cdots \oplus h_{k}^2 g_{\nn_k}$. Denotemos $\grad^{\mm}= \grad$ e $\Delta^{\mm} = \Delta$. Se $\phi \in \mathscr{C}^{\infty}(\bb)$ e $\psi \in \mathscr{C}^{\infty}(\nn_i)$, então
\begin{enumerate}[label=\color{blue}\normalfont\textbf{(\theenumi)}]
\item\label{GradPrimeiro} $\grad(\phi \circ \pi) = \grad_{\bb} \phi$
\item $\grad(\psi \circ \sigma_i) = \frac{\grad_{\nn_i} \psi}{h_i^2}$
\item $\Delta(\phi \circ \pi) = \Delta_{\bb} \phi + \sum_{1 \leq i \leq k} d_i \frac{g_{\bb}\left(\grad_{\bb} \phi, \grad_{\bb} h_i \right)}{h_i}$
\item $\Delta(\psi \circ \sigma_i) = \frac{\Delta_{\nn_i} \psi}{h_i^2}$
\end{enumerate}
\end{lema}

\begin{demm}
Fixe $p = \parent{p_0, q_1, \ldots, q_k } \in \mm$. Uma vez que $\phi \circ \pi$ é constante em $\{p_0 \} \times \nn_1 \times \ldots \times \nn_k$ seja qual for $p_0 \in \bb$, temos
\begin{align*}
\grad\parent{\phi \circ \pi}(p) &= \sum_{1 \leq i \leq r} \be_{(0, i)}(p) \parent{\phi \circ \pi} \, \be_{(0, i)}(p) \\
&= \sum_{1 \leq i \leq r} \dd \parent{\phi \circ \pi}_p \parent{\be_{(0, i)}(p)} \, \be_{(0, i)}(p) \\
&=  \sum_{1 \leq i \leq r} \dd \phi_{p_0}\parent{\be_{(0, i)}(p_0)}  \, \be_{(0, i)}(p) \\ 
&=  \sum_{1 \leq i \leq r}  \be_{(0, i)}(p_0) \parent{\phi} \, \be_{(0, i)}(p) \\
&= \parent{\grad_{\bb} \phi} (p)
\end{align*}
Analogamente,
\begin{align*}
\grad\parent{\psi \circ \sigma_i}(p) &= \sum_{1 \leq j \leq d_i} \bee_{(i, j)}(p)(\psi) \, \bee_{(i, j)}(p) \\
&= h_{i}^{-2} \, \parent{\grad_{\nn_i} \psi}(p)
\end{align*}
Da definição do Laplaciano, do item \ref{NablaWarp} do lema \cref{ConexaoDoWarped} e do item \ref{GradPrimeiro} do lema atual, segue também que
\begin{align*}
\Delta\parent{\phi \circ \pi} &= \sum_{1 \leq i \leq r} g\parent{ \nabla_{\be_{(0, i)}} \cn^{\bb} \phi, \be_{(0, i)} } + \sum_{\substack{1 \leq \alpha \leq k \\
1 \leq \beta \leq d_{\alpha}}} g\parent{ \cn_{\bee_{(\alpha, \beta)}} \cn^{\bb} \phi, \bee_{(\alpha, \beta)} } \\
&= \Delta_{\bb} \phi + \sum_{\substack{1 \leq \alpha \leq k \\
1 \leq \beta \leq d_{\alpha}}} g\parent{ \frac{\parent{\cn^{\bb} \phi}\parent{h_{\alpha}}}{h_{\alpha}} \, \bee_{(\alpha, \beta)} , \bee_{(\alpha, \beta)} } \\
&= \Delta_{\bb} \phi + \sum_{1 \leq \alpha \leq k} d_{\alpha} \frac{\parent{\cn^{\bb} \phi}\parent{h_{\alpha}}}{h_{\alpha}} \\
&=\Delta_{\bb} \phi + \sum_{1 \leq \alpha \leq k} d_{\alpha} \frac{g_{\bb} \parent{\nabla^{\bb} \phi, \cn^{\bb} h_{\alpha}}}{h_{\alpha}}
\end{align*}
Finalmente,
\begin{align*}
\Delta\parent{ \psi \circ \sigma_i} &= \sum_{1 \leq j \leq r} g\parent{ \cn_{\be_{(0, j)}} \cn \psi, \be_{(0, j)} } + \sum_{\substack{1 \leq \alpha \leq k \\
1 \leq \beta \leq d_{\alpha}}} g\parent{ \cn_{\bee_{(\alpha, \beta)}} \nabla \psi, \bee_{(\alpha, \beta)}} \\
&= \sum_{1 \leq j \leq r} g\parent{ \cn_{\be_{(0, j)}} \parent{ \frac{\cn^{\nn_i} \psi}{h_i^2}}, \be_{(0, j)}  } + \sum_{\substack{1 \leq \alpha \leq k \\
1 \leq \beta \leq d_{\alpha}}} g\parent{\cn_{\bee_{(\alpha, \beta)}} \parent{\frac{\cn^{\nn_i} \psi}{h_i^2} } , \bee_{(\alpha, \beta)}} \\
&= \sum_{1 \leq j \leq r} g\parent{ -\frac{2 \, \be_{(0, j)}(h_i)}{h_i^3} \, \cn^{\nn_i} \psi + \frac{1}{h_i^2} \, \cn_{\be_{(0, j)}} \cn^{\nn_i} \psi, \be_{(0, j)} } \\
&+\sum_{\substack{1 \leq \alpha \leq k \\
1 \leq \beta \leq d_{\alpha}}} h_i^{-4} \, g\parent{\cn_{\be_{(\alpha, \beta)}} \cn^{\nn_i} \psi, \be_{(\alpha, \beta)} } \\
&= \sum_{\substack{1 \leq \alpha \leq k \\
1 \leq \beta \leq d_{\alpha}}} h_i^{-2} \, g^{\nn_i}\parent{\cn_{\be_{(\alpha, \beta)}} \cn^{\nn_i} \psi, \be_{(\alpha, \beta)} } \\
&= h_i^{-2} \, \Delta_{\nn_i} \psi
\end{align*}
\end{demm}


\begin{lema}\label{RmDoWarped}
Seja $\mm = \bb \times_{h_1} \nn_1^{d_1} \times \cdots \times_{h_k} \nn_{k}^{d_k}$ um produto warped múltiplo com métrica $g = g_{\bb} \oplus h_1^2 g_{\nn_1} \oplus \cdots \oplus h_{k}^2 g_{\nn_k}$. Denotemos $\Rm^{\mm} = \Rm$ e tomemos $X, Y, Z \in \mathcal{L}(\bb)$, $V \in \mathcal{L}(\nn_{\alpha}), W \in \mathcal{L}(\nn_{\eta})$ e $U \in \mathcal{L}(\nn_{\beta})$. Então
\begin{enumerate}[label=\color{blue}\normalfont\textbf{(\theenumi)}]
\item\label{1RmWarp} $\Rm(X, Y)Z = \Rm_B(X, Y)Z$.
\item\label{2RmWarp} $\Rm(V, X)Y = -\frac{\left(\nabla^2_{\bb} h_{\alpha} \right)(X, Y)}{h_{\alpha}} V$.
\item\label{3RmWarp} $\Rm(X, V) W = \Rm(V, W)X = \Rm(V, X)W = 0$ sempre que $\alpha \notin \{ \eta \}$.
\item\label{4RmWarp} $\Rm(X, Y)V = 0$.
\item\label{5RmWarp} $\Rm(V, W)X = 0$ sempre que $\alpha = \eta$.
\item\label{6RmWarp} $\Rm(V, W)U = 0$ sempre que $\alpha \in \{\eta \} \neq \{\beta \}$.
\item\label{7RmWarp} $\Rm(U, V) W = -g(V, W) \, \frac{g_{\bb}(\grad_{\bb} h_{\alpha}, \grad_{\bb} h_{\beta})}{h_{\alpha} h_{\beta}} \, U$ sempre que $\alpha \in \{ \eta \} \neq \{ \beta \}$. 
\item\label{sinalerrado} $\Rm(X, V)W = -\frac{g(V, W)}{h_{\alpha}} \nabla^{\bb}_X(\grad_{\bb} h_{\alpha})$ sempre que $\alpha \in \{ \eta \}$.
\item\label{9doRmWarped} $\Rm(V, W)U = \Rm_{\nn_{\alpha}}(V, W)U + \frac{\| \grad_{\bb} h_{\alpha} \|^2}{\parent{h_{\alpha}^2}} \cdot \left(g(V, U)W - g(W, U)V \right)$ sempre que $\{\alpha, \eta \}= \{\beta \}$.
\end{enumerate}
\end{lema}

\begin{demm}
O item \ref{1RmWarp} é uma consequência direta do item \ref{nablaXYWarp} do lema \cref{ConexaoDoWarped}. Para provar o item \ref{2RmWarp}, note inicialmente que $[X, V] = 0$ como consequência imediata do lema \cref{RelBrack}, de forma que 
\begin{align*}
\Rm(V, X)Y &= \cn_V \cn_X Y - \cn_X \cn_V Y \\
&= \cn_V \cn^{\bb}_X Y - \cn_X \parent{\frac{Y(h_{\alpha})}{h_{\alpha}} V } \\
&= \frac{\parent{\cn^{\bb}_X Y}(h_{\alpha}) }{h_{\alpha}} \, V - X \parent{\frac{Y\parent{h_{\alpha}} }{h_{\alpha}} } V - \frac{Y\parent{h_{\alpha}} }{h_{\alpha}} \, \frac{X\parent{h_{\alpha}} }{h_{\alpha}} \, V \\
&= \frac{\cn_{\cn^{\bb}_X Y} \parent{h_{\alpha}}}{h_{\alpha}} \, V - \frac{X \parent{Y\parent{h_{\alpha}}}}{h_{\alpha}} \, V + \frac{X \parent{h_{\alpha}}}{h_{\alpha}^2} \, Y\parent{h_{\alpha}} \, V - \frac{X\parent{h_{\alpha}} \, Y\parent{ h_{\alpha}}}{h_{\alpha}^2} \, V \\
&=- \frac{\parent{\Hess_g \parent{h_{\alpha}}}(X, Y) }{h_{\alpha}} \, V
\end{align*}
O item \ref{3RmWarp} segue como consequência direta do item \ref{NablaVWdoWarp} do lema \cref{ConexaoDoWarped}. Agora, segue do item \ref{NablaWarp} do lema \cref{ConexaoDoWarped} que
\begin{align*}
\cn_X \cn_Y V - \cn_Y \cn_X V &= \cn_X \parent{ \frac{Y \parent{h_{\alpha} }}{h_{\alpha}}  \, V} - \cn_Y \parent{ \frac{X \parent{h_{\alpha} }}{h_{\alpha}} \, V} \\
&= X \parent{\frac{Y \parent{h_{\alpha} }}{h_{\alpha}} } \, V + \frac{Y \parent{h_{\alpha} }}{h_{\alpha}}  \, \cn_X V - Y \parent{\frac{X \parent{h_{\alpha} }}{h_{\alpha}} } \, V  - \frac{X \parent{h_{\alpha} }}{h_{\alpha}} \, \cn_Y V \\
&= \frac{ X\parent{Y\parent{h_{\alpha}} } }{h_{\alpha}}  \, V - \frac{X\parent{h_{\alpha}}}{\parent{h_{\alpha}}^2} \, Y\parent{h_{\alpha}} \, V + \frac{Y\parent{h_{\alpha}} }{h_{\alpha}} \, \frac{X\parent{h_{\alpha}} }{h_{\alpha}} \, V \\
&-\frac{ Y\parent{X\parent{h_{\alpha}} } }{h_{\alpha}}  \, V + \frac{X\parent{h_{\alpha}}}{\parent{h_{\alpha}}^2} \, Y\parent{h_{\alpha}} \, V  - \frac{X\parent{h_{\alpha}} }{h_{\alpha}} \, \frac{Y\parent{h_{\alpha}} }{h_{\alpha}} \, V  \\
&= \frac{[X, Y] \parent{h_{\alpha}}}{h_{\alpha}} \, V \\
&= \nabla_{[X, Y]} V
\end{align*}
e portanto $\Rm(X, Y)V =0$, como afirmado no item \ref{4RmWarp}. O item \ref{5RmWarp} é uma consequência simples do item \ref{NablaWarp} do lema \cref{ConexaoDoWarped}. De fato, 
\begin{align*}
\Rm(V, W)X &= \cn_V \cn_W X - \cn_W \cn_V X - \cn_{[V,W]}X \\
&= \cn_V \parent{ \frac{X\parent{h_{\alpha}}}{h_\alpha} \, W} - \cn_W \parent{ \frac{X\parent{h_{\alpha}}}{h_\alpha} \, V} - \frac{X\parent{h_{\alpha}}}{h_\alpha} \, [V, W] \\
&= \frac{X\parent{h_{\alpha}}}{h_\alpha} \, \parent{ \cn_V W - \cn_W V - [V, W] } \\
&=0
\end{align*} 
O item \ref{6RmWarp} é uma consequência direta dos itens \ref{NablaVWdoWarp} e \ref{nablaXYWarp} do lema \cref{ConexaoDoWarped}. Para provar o item \ref{7RmWarp}, note que novamente como consequência do lema \cref{RelBrack}, temos $[U, V] = 0$, de forma que usando o lema \cref{ConexaoDoWarped}, obtemos:
\begin{align*}
\Rm(U, V)W &= \cn_U \cn_V W - \cn_V \Munderbrace{\cn_U W}{=0} \\
&=\cn_U \left( \cn^{\nn_{\alpha}}_V W - \frac{g(V, W)}{h_{\alpha}} \, \cn^{\bb} h_{\alpha} \right) \\
&= -\frac{g(V, W)}{h_{\alpha}} \, \cn_U \cn^{\bb} h_{\alpha} \\
&= -\frac{g(V, W)}{h_{\alpha}} \, \frac{\parent{ \cn^{\bb} h_{\alpha} } \parent{h_{\beta}}}{h_{\beta}} \, U \\
&= -g(V, W) \, \frac{g_{\bb}(\grad_{\bb} h_{\alpha}, \grad_{\bb} h_{\beta})}{h_{\alpha} h_{\beta}} \, U
\end{align*}
Iremos agora provar o item \ref{sinalerrado}. Primeiramente, temos
\begin{align*}
\cn_X \cn_V W &= \cn_X \parent{\cn^{\nn_{\alpha}}_{V} W - \frac{g(V, W)}{h_{{\alpha}} } \,  \cn^{\bb} h_{\alpha} } \\
&= \frac{X\parent{ h_{\alpha}}}{h_{\alpha}} \, \cn^{\nn_{\alpha}}_{V} W - X \parent{ \frac{g(V, W)}{h_{\alpha}} } \, \cn^{\bb} h_{\alpha} -  \frac{g(V, W)}{h_{\alpha}} \, \cn_X \cn^{\bb} h_{\alpha} \\
&= \frac{X\parent{ h_{\alpha}}}{h_{\alpha}} \, \cn^{\nn_{\alpha}}_{V} W - \frac{\parent{  g\parent{\nabla_X V, W   } +  g\parent{V, \nabla_X W   }    }}{h_{\alpha}} \, \nabla^{\bb} h_{\alpha} + \frac{X \parent{h_{\alpha}}   }{\parent{h_{\alpha}}^2} \, g(V, W) \, \cn^{\bb} h_{\alpha} \\
&- \frac{g(V, W)}{h_{\alpha}} \cn^{\bb}_X \cn^{\bb} h_{\alpha} \\
&=  \frac{X\parent{ h_{\alpha}}}{h_{\alpha}} \, \cn^{\nn_{\alpha}}_{V} W - 2 \, \frac{X\parent{ h_{\alpha}}}{\parent{h_{\alpha}}^2} \, g(V, W) \, \cn^{\bb} h_{\alpha} + \frac{X\parent{ h_{\alpha}}}{\parent{h_{\alpha}}^2} \, g(V, W) \, \cn^{\bb} h_{\alpha} - \frac{g(V, W)}{h_{\alpha}} \cn^{\bb}_X \cn^{\bb} h_{\alpha} \\
&=  \frac{X\parent{ h_{\alpha}}}{h_{\alpha}} \, \cn^{\nn_{\alpha}}_{V} W -  \, \frac{X\parent{ h_{\alpha}}}{\parent{h_{\alpha}}^2} \, g(V, W) \, \cn^{\bb} h_{\alpha} - \frac{g(V, W)}{h_{\alpha}} \cn^{\bb}_X \cn^{\bb} h_{\alpha}
\end{align*}
E também:
\begin{align*}
\nabla_V \cn_X W &= \cn_V \parent{\frac{X \parent{h_{\alpha}} }{h_{\alpha}} W } \\
&=\frac{X \parent{h_{\alpha}} }{h_{\alpha}} \parent{ \cn^{\nn_{\alpha}}_V W - \frac{g(V, W)}{h_{\alpha}} \, \cn^{\bb} h_{\alpha}  } \\
&= \frac{X \parent{h_{\alpha}} }{h_{\alpha}}  \, \cn^{\nn_{\alpha}}_V W  - \frac{X\parent{ h_{\alpha}}}{\parent{h_{\alpha}}^2} \, g(V, W) \, \cn^{\bb} h_{\alpha}
\end{align*}
Como $[X, V] = 0$, segue então que
\[
\Rm(X, V)W = -\frac{g(V, W)}{h_{\alpha}} \, \nabla^{\bb}_X(\grad_{\bb} h_{\alpha})
\]
Finalmente, para provar \ref{9doRmWarped}, note primeiramente que $\Rm(V, W)U \in \mathcal{L}(\nn_{\alpha})$, já que dados $X \in \mathcal{L}(\bb)$ e $L \in \mathcal{L}(\nn_{\xi})$ com $\xi \neq \alpha$, temos
\begin{align*}
&g\parent{\Rm(V, W)U, X } = -g\parent{\Rm(V, W)X, U } = 0 , \text{ pelo item \ref{5RmWarp}}\\
&g\parent{\Rm(V, W)U, L } = -g\parent{\Rm(V, W)L, U } = 0, \text{  pelo item \ref{6RmWarp}}
\end{align*}
Segue então da equação de Gauss e do item \ref{NablaVWdoWarp} do lema \cref{ConexaoDoWarped} que dado qualquer $C \in \mathcal{L}(\nn_{\alpha})$, temos
\begin{align*}
g\parent{\Rm(V, W)U, C } &= \parent{h_{\alpha}}^2 \, \Rm^{\nn_{\alpha}}(V, W, U, C) - g\parent{ \segf(V, C), \segf(W, U) } + g\parent{ \segf(V, U), \segf(W, C) } \\
&= \parent{h_{\alpha}}^2 \, \Rm^{\nn_{\alpha}}(V, W, U, C) - \frac{g(V, C) \, g(W, U)}{\parent{h_{\alpha}}^2} \, \| \cn^{\bb} h_{\alpha} \|^2 + \frac{g(V, U) \, g(W, C)}{\parent{h_{\alpha}}^2} \, \| \cn^{\bb} h_{\alpha} \|^2  
\end{align*}
Equivalentemente, como $\Rm(V, W)U \in \mathcal{L}(\nn_{\alpha})$, 
\[
\flat^{g} \parent{\Rm(V, W)U } = \flat^{g} \parent{ \Rm^{\nn_{\alpha}}(V, W) U + \frac{\| \nabla^{\bb} h_{\alpha} \|^2}{\parent{h_{\alpha}}^2} \cdot \colch{g(V, U) \, W - g(W, U) \, V} } 
\]
Como $\flat^{g}$ é um isomorfismo em cada fibra de $T \mm$, segue, como queríamos mostrar, que
\[
\Rm(V, W)U = \Rm^{\nn_{\alpha}}(V, W) U + \frac{\| \nabla^{\bb} h_{\alpha} \|^2}{\parent{h_{\alpha}}^2} \cdot \colch{g(V, U) \, W - g(W, U) \, V} 
\]
\end{demm}

\begin{lema}\label{TensorRicciDoWarped}
Seja $\mm = \bb \times_{h_1} \nn_1^{d_1} \times \cdots \times_{h_k} \nn_{k}^{d_k}$ um produto warped múltiplo com métrica $g = g_{\bb} \oplus h_1^2 g_{\nn_1} \oplus \cdots \oplus h_{k}^2 g_{\nn_k}$. Suponha que $X, Y, Z \in \mathcal{L}(\bb)$, $V \in \mathcal{L}(\nn_{\alpha})$ e $W \in \mathcal{L}(\nn_{\eta})$. Então:
\begin{enumerate}[label=\color{blue}\normalfont\textbf{(\theenumi)}]
\item\label{RicXY} $\Ric(X, Y) = \Ric_{\bb}(X, Y) - \sum_{1 \leq \mu \leq k} \frac{d_{\mu}}{h_{\mu}} \nabla^2_{\bb}(h_{\mu})(X, Y)$.
\item\label{RicXV} $\Ric(X, V) = 0$.
\item\label{RicVWd} $\Ric(V, W) = 0$ se $\alpha \neq \eta$.
\item\label{RicVWi} \[
 \Ric(V, W) = \Ric^{\nn_{\alpha}}\parent{ V, W } -
\begin{split}\hspace{-7.9cm}
    \left(
    \begin{aligned}
          &\frac{\Delta_{\bb} h_{\alpha}}{h_{\alpha}} + \parent{d_{\alpha} - 1} \, \frac{\| \cn^{\bb} h_{\alpha} \|^2}{\parent{h_{\alpha}}^2} \\[0.5cm]
         &+ \sum_{\substack{1 \leq \gamma \leq k \\
\gamma \neq \alpha}} d_{\gamma} \, \frac{g_{\bb} \parent{ \cn^{\bb} h_{\gamma}, \cn^{\bb} h_{\alpha} }}{h_{\gamma} \, h_{\alpha}}
    \end{aligned}
    \right) g\parent{ V, W }, \text{ se } \alpha = \eta.
\end{split}
\]
\end{enumerate}

\end{lema}

\begin{demm}
Primeiramente, temos
\begin{align*}
\Ric(X, Y) &= \sum_{1 \leq i \leq r} \Rm\parent{\be_{(0, i)}, X, Y, \be_{(0, i)}} + \sum_{\substack{1 \leq \mu \leq k \\ 
1 \leq \beta \leq d_{\mu}}} \Rm\parent{ \bee_{(\mu, \beta)}, X, Y, \bee_{(\mu, \beta)} } \\
&= \Ric^{\bb}(X, Y)  + \sum_{\substack{1 \leq \mu \leq k \\ 
1 \leq \beta \leq d_{\mu}}} g\parent{ -\frac{ \parent{\cn^2_{\bb} h_{\mu} }(X, Y)}{h_{\mu}} \, \bee_{(\mu, \beta)}, \bee_{(\mu, \beta)} } \\
&= \Ric^{\bb}(X, Y)  - \sum_{1 \leq \mu \leq k }  \frac{d_{\mu}}{h_{\mu}} \, \parent{ \cn^{2}_{\bb} h_{\mu} }(X, Y)
\end{align*}
Pela $\mathscr{C}^{\infty}(\mm)$-bilinearidade de $\Ric$, para provar os itens restantes podemos supor sem perda de generalidade que $V = \bee_{(\alpha, \beta)}$ e $W = \bee_{(\eta, \xi)}$. Temos
\begin{align*}
\Ric(X, V) &= \sum_{1 \leq i \leq r} g \parent{ \Rm \parent{ \be_{(0, i)}, X }V, \be_{(0, i)} } + \sum_{ \substack{1 \leq \gamma \leq k \\ 
1 \leq \ell \leq d_{\gamma}}} g \parent{ \Rm \parent{ \be_{(\gamma, \ell)}, X}V, \be_{(\gamma, \ell)}} \\
&= - \sum_{1 \leq i \leq r}  \Munderbrace{g \parent{ \Rm \parent{ \be_{(0, i)}, X }\be_{(0, i)} , V}}{=0, \text{ por \ref{1RmWarp} de \cref{RmDoWarped}}} - \sum_{ \substack{1 \leq \gamma \leq k \\ 
1 \leq \ell \leq d_{\gamma}}}  \Munderbrace{g \parent{  \Rm\parent{ X,  \be_{(\gamma, \ell)} } \be_{(\alpha, \beta)} , \be_{(\gamma, \ell)} }}{=0, \text{ por \ref{3RmWarp} e \ref{sinalerrado} de \cref{RmDoWarped}}} \\
&= 0
\end{align*}
Se $\alpha \neq \eta$, temos:
\begin{align*}
\Ric\parent{\bee_{(\alpha, \beta)}, \bee_{(\eta, \xi)} } &= \sum_{1 \leq i \leq r} \Munderbrace{g\parent{ \Rm\parent{\be_{(0, i)}, \bee_{(\alpha, \beta)}} \bee_{(\eta, \xi)}, \be_{(0, i)}}}{=0, \text{ por \ref{3RmWarp} de \cref{RmDoWarped}}} + \sum_{\substack{1 \leq \gamma \leq k \\
1 \leq p \leq d_{\gamma}} } g \parent{ \Rmm{\bee_{(\gamma, p)}}{\bee_{(\alpha, \beta)}}{\bee_{(\eta, \xi)}}{\bee_{(\gamma, p)}}}
\end{align*}
É óbvio que os termos do último somatório do lado direito acima todos se anulam. De fato, se $\gamma = \alpha$ isso é absolutamente trivial, e quando $\gamma, \alpha$ e $\eta$ são todos distintos, o item \ref{NablaVWdoWarp} do lema \cref{ConexaoDoWarped} garante que
\[
 \Rm\parent{ \bee_{(\gamma, p)}, \bee_{(\alpha, \beta)}} \bee_{(\eta, \xi)} = 0
\]
Agora, quando $\alpha = \eta$, temos
\begin{align*}
\Ric\parent{\bee_{(\alpha, \beta)}, \bee_{(\alpha, \xi)} } &= \sum_{1 \leq i \leq r} g\parent{ \Rm\parent{\be_{(0, i)}, \bee_{(\alpha, \beta)}} \bee_{(\alpha, \xi)}, \be_{(0, i)}} + \sum_{\substack{1 \leq \gamma \leq k \\
1 \leq p \leq d_{\gamma}} } g \parent{ \Rmm{\bee_{(\gamma, p)}}{\bee_{(\alpha, \beta)}}{\bee_{(\alpha, \xi)}}{\bee_{(\gamma, p)}}} \\
&= \sum_{1 \leq i \leq r} g\parent{ \frac{-\delta_{\beta \xi}}{h_{\alpha}} \, \cn^{\bb}_{\be_{(0, i)}} \cn^{\bb} h_{\alpha}, \be_{(0, i)}} + \sum_{1 \leq p \leq d_{\alpha}} g \parent{ \Rmm{\bee_{(\alpha, p)}}{\bee_{(\alpha, \beta)}}{\bee_{(\alpha, \xi)}}{\bee_{(\alpha, p)}}} \\
&+ \sum_{\substack{1 \leq \gamma \leq k \\
\gamma \neq \alpha \\
1 \leq p \leq d_{\gamma}} } g \parent{ \Rmm{\bee_{(\gamma, p)}}{\bee_{(\alpha, \beta)}}{\bee_{(\alpha, \xi)}}{\bee_{(\gamma, p)}}} \\
&=-\frac{\delta_{\beta \xi}}{h_{\alpha}} \, \Delta_{\bb} h_{\alpha} \\
&+ \sum_{1 \leq p \leq d_{\alpha}} g \parent{ \Rm^{\nn_{\alpha}}\parent{ \bee_{(\alpha, p)}, \bee_{(\alpha, \beta)}} \bee_{(\alpha, \xi)} + \frac{\| \cn^{\bb} h_{\alpha} \|^2}{\parent{h_{\alpha}}^2} \, \colch{\delta_{p \xi} \, \bee_{(\alpha, \beta)} - \delta_{\beta \xi} \, \bee_{(\alpha, p)}} , \bee_{(\alpha, p)}  } \\
&-\sum_{\substack{1 \leq \gamma \leq k \\
\gamma \neq \alpha \\
1 \leq p \leq d_{\gamma}} } g \parent{ \delta_{\beta \xi} \, \frac{g_{\bb} \parent{ \cn^{\bb} h_{\gamma}, \cn^{\bb} h_{\alpha}  }}{h_{\gamma} \, h_{\alpha}} \bee_{(\gamma, p)},  \bee_{(\gamma, p)}} \\
&=-\frac{\delta_{\beta \xi}}{h_{\alpha}} \, \Delta_{\bb} h_{\alpha} + \Ric^{\nn_{\alpha}}\parent{ \bee_{(\alpha, \beta)}, \bee_{(\alpha, \xi)} } + \frac{\| \cn^{\bb} h_{\alpha} \|^2}{\parent{h_{\alpha}}^2} \, \delta_{\beta \xi} - \frac{\| \cn^{\bb} h_{\alpha} \|^2}{\parent{h_{\alpha}}^2} \, \delta_{\beta \xi} \, d_{\alpha} \\
&- \delta_{\beta \xi} \sum_{\substack{1 \leq \gamma \leq k \\
\gamma \neq \alpha}} d_{\gamma} \, \frac{g_{\bb} \parent{ \cn^{\bb} h_{\gamma}, \cn^{\bb} h_{\alpha} } }{h_{\gamma} \, h_{\alpha}} \\[1cm]
&=  \Ric^{\nn_{\alpha}}\parent{ \bee_{(\alpha, \beta)}, \bee_{(\alpha, \xi)} } -
\begin{split}\hspace{-10cm}
    \left(
    \begin{aligned}
          \frac{\Delta_{\bb} h_{\alpha}}{h_{\alpha}} &+ \parent{d_{\alpha} - 1} \, \frac{\| \cn^{\bb} h_{\alpha} \|^2}{\parent{h_{\alpha}}^2} \\[0.5cm]
         &+ \sum_{\substack{1 \leq \gamma \leq k \\
\gamma \neq \alpha}} d_{\gamma} \, \frac{g_{\bb} \parent{ \cn^{\bb} h_{\gamma}, \cn^{\bb} h_{\alpha} }}{h_{\gamma} \, h_{\alpha}}
    \end{aligned}
    \right) g\parent{ \bee_{(\alpha, \beta)}, \bee_{(\alpha, \xi)} } 
\end{split}
\end{align*}
\end{demm}
\begin{lema}\label{warped}
Seja $\mm = B \times_{h_1} \nn_1^{d_1} \times \cdots \times_{h_k} \nn_{k}^{d_k}$ um produto warped múltiplo com métrica $g = g_{B} \oplus h_1^2 g_{\nn_1} \oplus \cdots \oplus h_{k}^2 g_{\nn_k}$. Então a curvatura escalar de $\mm$ é dada por
\begin{equation}\label{ScalWarped}
\begin{aligned}
R = R_{B} &- 2 \sum_{1 \leq i \leq k} d_i \frac{\Delta_B h_i}{h_i} + \sum_{1 \leq i \leq k} \frac{R_{\nn_i}}{h_i^2} - \sum_{1 \leq i \leq k} d_i(d_i - 1) \frac{\| \grad_B h_i \|_B^2}{h_i^2} \\
&- \sum_{1 \leq i \leq k} \sum_{\substack{1 \leq \ell \leq k \\
\ell \neq i  \\
}} d_i d_{\ell} \frac{g_B(\grad_B h_i, \grad_B h_{\ell})}{h_i h_{\ell}}
\end{aligned}
\end{equation}
\end{lema}

\begin{demm}
Temos
\begin{align*}
R &= \sum_{1 \leq i \leq r} \Ric\parent{\be_{(0, i)}, \be_{(0, i)} } + \sum_{ \substack{1 \leq \alpha \leq k \\
1 \leq \varphi \leq d_{\alpha}}} \Ric\parent{ \bee_{(\alpha, \varphi)}, \bee_{(\alpha, \varphi)} } \\
&= R_{\bb} - \sum_{\substack{1 \leq \mu \leq k \\
1 \leq i \leq r}} \frac{d_{\mu}}{h_{\mu}} \, \parent{\nabla^2_{\bb} h_{\mu}}\parent{\be_{(0, i)}, \be_{(0, i)}} \\
&+\sum_{ \substack{1 \leq \alpha \leq k \\
1 \leq \varphi \leq d_{\alpha}}} \Ric^{\nn_{\alpha}}\parent{ \bee_{(\alpha, \varphi)}, \bee_{(\alpha, \varphi)} } - \begin{split}\hspace{-7.1cm}
    \sum_{\substack{1 \leq \alpha \leq k \\
    1 \leq \varphi \leq d_{\alpha}}}\left(
    \begin{aligned}
          \frac{\Delta_{\bb} h_{\alpha}}{h_{\alpha}} &+ \parent{d_{\alpha} - 1} \, \frac{\| \cn^{\bb} h_{\alpha} \|^2}{\parent{h_{\alpha}}^2} \\[0.5cm]
         &+ \sum_{\substack{1 \leq \gamma \leq k \\
\gamma \neq \alpha}} d_{\gamma} \, \frac{g_{\bb} \parent{ \cn^{\bb} h_{\gamma}, \cn^{\bb} h_{\alpha} }}{h_{\gamma} \, h_{\alpha}}
    \end{aligned}
    \right) g\parent{ \bee_{(\alpha, \varphi)}, \bee_{(\alpha, \varphi)} } 
\end{split} \\
&= R_{\bb} - 2 \, \sum_{1 \leq \mu \leq k} d_{\mu} \frac{\Delta_{\bb} h_{\mu}}{h_{\mu}} \, + \sum_{1 \leq \mu \leq k} \frac{R_{\nn_{\mu}}}{\parent{h_{\mu}}^2} - \sum_{1 \leq \mu \leq k} d_{\mu} \, \parent{ d_{\mu} - 1} \frac{\|\grad_{\bb} h_{\mu} \|^2}{\parent{h_{\mu}}^2} \\
&- \sum_{1 \leq \alpha \leq k} \sum_{\substack{1 \leq \gamma \leq k \\
\gamma \neq \alpha}} d_{\alpha} \, d_{\gamma} \,  \frac{g_{\bb} \parent{ \cn^{\bb} h_{\gamma}, \cn^{\bb} h_{\alpha} }}{h_{\gamma} \, h_{\alpha}}
\end{align*}
\end{demm}


\begin{exem}\label{FormaEspacialComoWarped}
Para este exemplo, lembramos primeiramente que uma variedade Riemanniana $\parent{\mm, g }$ tem curvatura seccional constante igual a $S \in \mathbb{R}$ se, e somente se, seu tensor de curvatura é dado por
\[
\Rm = S \, \parent{g \KN g}
\]
(onde $\KN$ denota o produto de Kulkarni-Nomizu), ou, equivalentemente, se e só se,
\[
 \Rm(X, Y, Z, W)=  S \, \parent{ g(X, W) \, g(Y, Z)  - g(X, Z) \, g(Y, W) }
 \]
sejam quais forem $X, Y, Z, W \in \Gamma\parent{T \mm}$. Agora, denotando
\[
\mathbb{Q}^n(\kappa) \doteq \begin{cases}
\mathbb{R}^n, \text{ se } \kappa = 0 \\
\mathbb{S}^n, \text{ se } \kappa = 1 \\
\mathbb{H}^n, \text{ se } \kappa = -1 
\end{cases}
\]
Temos (conforme demonstrado em \mycitep{Ortega}) que o tensor Riemanniano de $\mathcal{I} \times_{h} \mathbb{Q}^n(\kappa)$ (onde $\mathcal{I} \subset \mathbb{R}$ é um intervalo aberto e $h$ é uma função real suave e positiva definida em $\mathcal{I}$) é dado por 
\[ \begin{aligned}
\Rm(X, Y, Z, W) &= \parent{ \frac{\parent{h'}^2 - \kappa}{h^2} \circ \pi_{\mathcal{I}}} \, \parent{ g(X, Z) \, g(Y, W) - g(X, W) \, g(Y, Z)} \\
&+ \parent{\frac{h \, h'' - \parent{h'}^2 + \kappa}{h^2}  \circ \pi_{\mathcal{I}}} \, \begin{split}\hspace{0cm}
    \left(
    \begin{aligned}
          &g(X, Z) \, g\parent{Y, \partial_t} \, g\parent{W, \partial_t} - g(Y, Z) \, g\parent{X, \partial_t} \,  g\parent{W, \partial_t} \\[0.5cm]
         &-g(X, W) \, g\parent{Y, \partial_t} \, g\parent{Z, \partial_t} + g(Y, W) \, g\parent{X, \partial_t} \, g\parent{Z, \partial_t}
    \end{aligned}
    \right) 
\end{split}
\end{aligned}
\]
Em particular, $\mathcal{I} \times_{h} \mathbb{Q}^n(\kappa)$ tem curvatura seccional constante igual a $C \in \mathbb{R}$ se, e somente se, 
\[
-C = \frac{\parent{h'}^2 - \kappa}{h^2}  \text{ é constante e } \frac{h''}{h} = \frac{\parent{h'}^2 - \kappa}{h^2}
\]
Consequentemente, 
\begin{align*}
&\text{$\mathbb{S}^n$ é localmente isométrico a $\mathcal{I} \times_{\operatorname{sen(t)}} \mathbb{S}^{n-1}$} \\
&\text{$\mathbb{H}^n$ é localmente isométrico a $\mathcal{I} \times_{e^{t}} \mathbb{R}^{n-1}$ e a  $\mathcal{I} \times_{\operatorname{senh}(t)} \mathbb{S}^{n-1}$} \\
&\text{$\mathbb{R}^n$ é localmente isométrico a $\mathcal{I} \times_{t} \mathbb{S}^{n-1}$}
\end{align*}
\end{exem}


Pelo lema a seguir, a variedade Riemanniana do exemplo \cref{BryantSoliton} é localmente conformemente plana.

\begin{lema}\label{LemaGarciaRio}
Seja $\mm = \mathcal{I} \times_{h} \nn$ um produto warped. Então
\[
\mm \text{ é localmente conformemente plana} \iff \parent{ \nn, g_{\nn} } \text{ tem curvatura seccional constante}
\]
\end{lema}

\begin{demm}
Consulte \mycitep{GarciaRio}.
\end{demm}

\begin{exem}[Sóliton de Bryant]\label{BryantSoliton}
Seja $g_{\mathbb{S}^{n-1}}$ a métrica usual na esfera redonda unitária $(n-1)$-dimensional. Procuraremos sólitons de Ricci steady que surgem como produtos warped em $(0, \infty) \times \mathbb{S}^{n-1}$. Consideremos então métricas da forma
\[
g = \dd r^2 + (\phi(r))^2 g_{\mathbb{S}^{n-1}}
\]
Tomando um referencial ortonormal local em $\mathbb{S}^{n-1}$, digamos \[
\left\{\frac{\partial}{\partial \theta^i} \right\}_{1 \leq i \leq n-1}
\]
vemos que $\left\{\frac{\partial}{\partial r}, \frac{1}{\phi} \frac{\partial}{\partial \theta^i} \right\}_{1 \leq i \leq n -1}$ é um referencial ortonormal local em $(0, \infty) \times_{\phi} \mathbb{S}^{n-1}$. Pelo \cref{sinalerrado} do lema \cref{RmDoWarped}, vemos que a curvatura radial de um plano passando pelo vetor radial $\frac{\partial}{\partial r}$ é dada por
\[ \begin{aligned}
K_{{\rm rad}} = K\left(\frac{\partial}{\partial r}, \frac{1}{\phi} \frac{\partial}{\partial \theta^i}\right) &= g\left(\Rm\left( \frac{\partial}{\partial r}, \frac{1}{\phi} \frac{\partial}{\partial \theta^i}\right)\frac{1}{\phi} \frac{\partial}{\partial \theta^i} , \frac{\partial}{\partial r}\right) \\
&= \frac{1}{\phi^2} \cdot g(\Rm(\partial_r, \partial_{\theta^i}) \partial_{\theta^i}, \partial_r) \\
&= -\frac{1}{\phi^2} \cdot \frac{\phi^2}{\phi} \cdot \phi'' \\
&= -\frac{\phi''}{\phi}
\end{aligned}
\]
Analogamente, usando o item \cref{9doRmWarped} do lema do lema \cref{RmDoWarped}, vemos que a curvatura seccional de um plano $P_{{\rm sph}}$ perpendicular a $\frac{\partial}{\partial r}$ é dada por
\[ \begin{aligned}
K_{{\rm sph}} = K\left(\frac{1}{\phi} \partial_{\theta^i}, \frac{1}{\phi} \partial_{\theta^j} \right) &= \frac{1}{\phi^4} \cdot g\left( \Rm(\partial_{\theta^i}, \partial_{\theta^j}) \partial_{\theta^j}, \partial_{\theta^i} \right) \\
&= \frac{1}{\phi^4} \cdot \phi^2 \cdot g_{\mathbb{S}^{n-1}} \left( [\pi_{\mathbb{S}^{n-1}}^{*} \Rm]\left(\partial_{\theta^i}, \partial_{\theta^j}) \partial_{\theta^j} \right) , \partial_{\theta^i}\right) \\
&= \frac{1}{\phi^2} \cdot \left(1 - \frac{(\phi')^2}{\phi^2} \cdot \phi^2 \right) \\
&= \frac{1-(\phi')^2}{\phi^2}
\end{aligned}
\]
Portanto
\[
\Ric\left(\frac{\partial}{\partial r}, \frac{\partial}{\partial r} \right) = \sum_{1 \leq i \leq n -1} K_{{\rm rad}} = -(n-1) \frac{\phi''}{\phi}
\]
e 
\[ \begin{aligned}
\Ric\left(\frac{\partial}{\partial \theta^i}, \frac{\partial}{\partial \theta^j} \right) &= \phi^2 \cdot \Ric\left(\frac{1}{\phi} \cdot \frac{\partial}{\partial \theta^i}, \frac{1}{\phi} \cdot \frac{\partial}{\partial \theta^j} \right) \\
&= \phi^2 \cdot \left(\left[\sum_{\substack{1 \leq i \leq n-2 \\
i \leq j}} K_{{\rm sph}} \right] + K_{{\rm rad}}\right) \\
&= (n-2) \left( 1 - (\phi')^2 \right) - \phi \phi''
\end{aligned}
\]
Concluímos então que
\[
\Ric(g) = -(n-1) \frac{\phi''}{\phi} \cdot \dd r^2 + \left(  (n-2) \left( 1 - (\phi')^2 \right) - \phi \phi'' \right) g_{\mathbb{S}^{n-1}}
\]
Agora, como consequência direta do lema \cref{ConexWarped}, temos também
\[
\nabla^2 f = f''(r) \cdot \dd r^2 + \phi \phi' f' \cdot  g_{\mathbb{S}^{n-1}}
\]
Vemos que a equação para os sólitons de Ricci steady $\Ric(g) + \nabla^2 f = 0$ nesse caso é equivalente ao seguinte sistema de EDOs de segunda ordem:
\[
\begin{cases}
f^{\prime \prime}=(n-1) \frac{\phi^{\prime \prime}}{\phi} \\
\phi \phi^{\prime} f^{\prime}=-(n-2)\left(1-\left(\phi^{\prime}\right)^{2}\right)+\phi \phi^{\prime \prime}
\end{cases}
\]
Estudando detalhadamente esse sistema, pode-se provar a existência de um sóliton de Ricci gradiente steady rotacionalmente simétrico e completo, que é único a menos de homotetias. 

\end{exem}



\begin{thebibliography}{9}

{\bfseries
\color{teal}

\bibitem{MeuTextoLivre}
\bl{
\textbf{Horácio, M.A.R.M.} \emph{One chart to rule them all!} Texto encontrado em página pessoal. Disponível em: \href{https://sagangromov.github.io/assets/pdf/OneChart.pdf}{\textbf{https://sagangromov.github.io/assets/pdf/OneChart.pdf}}. Acessado em 15 de fevereiro de 2023.
}



\bibitem{TuRiem}
\bl{
\textbf{Tu, Loring W.} Differential geometry. Connections, curvature, and characteristic classes. Graduate Texts in Mathematics, 275. \emph{Springer, Cham,} 2017. xvi+346 pp. ISBN: 978-3-319-55082-4; 978-3-319-55084-8.
}



\bibitem{dascontaswarped} \bl{\textbf{Dobarro, Fernando; Ünal, Bülent.} Curvature of multiply warped products. \emph{J. Geom. Phys.} \textbf{55} (2005), no. 1, 75--106. \href{https://mathscinet.ams.org/mathscinet-getitem?mr=2157416}{\textbf{MR2157416.}}}


\bibitem{Ortega}
\bl{
\textbf{Marie-Amélie Lawn, Miguel Ortega,} A fundamental theorem for hypersurfaces in semi-Riemannian warped products, Journal of Geometry and Physics, Volume \textbf{90}, 2015, Pages 55-70, ISSN 0393-0440,
\href{https://www.sciencedirect.com/science/article/pii/S0393044015000030}{\bf{https://doi.org/10.1016/j.geomphys.2015.01.002.}}
}

\bibitem{GarciaRio}
\bl{
\textbf{Brozos-Vázquez, M.; García-Río, E.; Vázquez-Lorenzo, R.} Warped product metrics and locally conformally flat structures. \emph{Mat. Contemp.} 28 (2005), 91--110. \href{http://www.ams.org/mathscinet-getitem?mr=2195191}{\bf{MR2195191.}}
}




}




\end{thebibliography}

\end{document}
